{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e3e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== References used in this notebook ===\n",
      "[1] 01_regression_evaluation.ipynb — Regression metrics & analysis (Task 1 follow-up).\n",
      "[2] 02_classification_evaluation.ipynb — Classification metrics & analysis (Task 3 follow-up).\n",
      "\n",
      "Loaded prior notebooks: NO (using local fallbacks)\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Notebook 7 — Reference & Reuse from Notebooks 01 & 02\n",
    "# ===========================================================\n",
    "# This cell:\n",
    "# 1) Attempts to execute prior notebooks to pull in any helper functions (metrics, plotting, etc.)\n",
    "# 2) Provides safe fallbacks for regression & classification metrics if those notebooks\n",
    "#    don't expose functions in the global namespace.\n",
    "# 3) Prints a short \"References\" section for report traceability.\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import os, builtins, types, inspect, sys\n",
    "import numpy as np\n",
    "\n",
    "# --- 1) Try to execute prior notebooks so their functions land in the global namespace ---\n",
    "possible_paths = [\n",
    "    \"/mnt/data/01_regression_evaluation.ipynb\",\n",
    "    \"/mnt/data/02_classification_evaluation.ipynb\",\n",
    "    \"01_regression_evaluation.ipynb\",\n",
    "    \"02_classification_evaluation.ipynb\",\n",
    "    \"/mnt/data/01_linear_regression (1).ipynb\",  # just in case you still want this one\n",
    "]\n",
    "\n",
    "# Jupyter magic runner, if available  \n",
    "def _run_notebook(nb_path):\n",
    "    try:\n",
    "        get_ipython().run_line_magic(\"run\", f'\"{nb_path}\"')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[REF] Could not run: {nb_path} -> {e}\")\n",
    "        return False\n",
    "\n",
    "ran_any = False\n",
    "for p in possible_paths:\n",
    "    if os.path.exists(p) and p.lower().endswith(\".ipynb\"):\n",
    "        ok = _run_notebook(p)\n",
    "        ran_any = ran_any or ok\n",
    "\n",
    "# --- 2) Safe fallbacks (only define if missing) ------------------------------------------\n",
    "def _maybe_define(name, fn):\n",
    "    if not hasattr(builtins, name) and name not in globals():\n",
    "        globals()[name] = fn\n",
    "\n",
    "# Regression metrics fallbacks\n",
    "_maybe_define = _maybe_define  # alias\n",
    "\n",
    "_maybe_define(\"mse\", lambda y_true, y_pred: float(np.mean((np.asarray(y_true) - np.asarray(y_pred))**2)))\n",
    "_maybe_define(\"mae\", lambda y_true, y_pred: float(np.mean(np.abs(np.asarray(y_true) - np.asarray(y_pred)))))\n",
    "def _rmse(y_true, y_pred): \n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "_maybe_define(\"rmse\", _rmse)\n",
    "def _r2(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    ss_res = float(np.sum((y_true - y_pred)**2))\n",
    "    ss_tot = float(np.sum((y_true - np.mean(y_true))**2))\n",
    "    return 1.0 - ss_res/ss_tot if ss_tot != 0 else 0.0\n",
    "_maybe_define(\"r2\", _r2)\n",
    "\n",
    "# Classification metrics fallbacks (vectorized; robust for edge cases)\n",
    "def _confusion_matrix_np(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(int); y_pred = np.asarray(y_pred).astype(int)\n",
    "    # binary only\n",
    "    tn = int(np.sum((y_true == 0) & (y_pred == 0)))\n",
    "    fp = int(np.sum((y_true == 0) & (y_pred == 1)))\n",
    "    fn = int(np.sum((y_true == 1) & (y_pred == 0)))\n",
    "    tp = int(np.sum((y_true == 1) & (y_pred == 1)))\n",
    "    return np.array([[tn, fp], [fn, tp]], dtype=int)\n",
    "_maybe_define(\"confusion_matrix_np\", _confusion_matrix_np)\n",
    "\n",
    "def _accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(int); y_pred = np.asarray(y_pred).astype(int)\n",
    "    return float(np.mean(y_true == y_pred))\n",
    "_maybe_define(\"accuracy_np\", _accuracy)\n",
    "\n",
    "def _precision(y_true, y_pred, zero_division=0.0):\n",
    "    cm = _confusion_matrix_np(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    denom = (tp + fp)\n",
    "    return float(tp/denom) if denom else float(zero_division)\n",
    "_maybe_define(\"precision_np\", _precision)\n",
    "\n",
    "def _recall(y_true, y_pred, zero_division=0.0):\n",
    "    cm = _confusion_matrix_np(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    denom = (tp + fn)\n",
    "    return float(tp/denom) if denom else float(zero_division)\n",
    "_maybe_define(\"recall_np\", _recall)\n",
    "\n",
    "def _f1(y_true, y_pred, zero_division=0.0):\n",
    "    p = _precision(y_true, y_pred, zero_division=zero_division)\n",
    "    r = _recall(y_true, y_pred, zero_division=zero_division)\n",
    "    denom = (p + r)\n",
    "    return float(2*p*r/denom) if denom else float(zero_division)\n",
    "_maybe_define(\"f1_np\", _f1)\n",
    "\n",
    "def _tpr_fpr(y_true, y_pred):\n",
    "    cm = _confusion_matrix_np(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tpr = float(tp/(tp+fn)) if (tp+fn) else 0.0\n",
    "    fpr = float(fp/(fp+tn)) if (fp+tn) else 0.0\n",
    "    return tpr, fpr\n",
    "_maybe_define(\"tpr_fpr_np\", _tpr_fpr)\n",
    "\n",
    "# Small helper to binarize probabilities by threshold (used across notebooks)\n",
    "def _binarize(p, thr=0.5):\n",
    "    return (np.asarray(p) >= float(thr)).astype(int)\n",
    "_maybe_define(\"binarize\", _binarize)\n",
    "\n",
    "# --- 3) Human-readable references you can print in your report/notebook ------------------\n",
    "refs = [\n",
    "    \"01_regression_evaluation.ipynb — Regression metrics & analysis (Task 1 follow-up).\",\n",
    "    \"02_classification_evaluation.ipynb — Classification metrics & analysis (Task 3 follow-up).\",\n",
    "]\n",
    "print(\"\\n=== References used in this notebook ===\")\n",
    "for i, r in enumerate(refs, 1):\n",
    "    print(f\"[{i}] {r}\")\n",
    "\n",
    "print(\"\\nLoaded prior notebooks:\", \"YES\" if ran_any else \"NO (using local fallbacks)\")\n",
    "\n",
    "# After this cell:\n",
    "# - Your previously-defined functions (if any) from 01/02 will already be in the global namespace.\n",
    "# - Missing pieces are covered by the safe fallbacks above.\n",
    "# - Continue with Notebook 7’s unified evaluation code (metrics/curves/threshold analysis).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
